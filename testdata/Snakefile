import os
import json
import yaml
import shutil

from pathlib import Path

# the str is needed as when running from github workflow.current_basedir is a Githubfile, not a string or a path so os.path objects
configfile: os.path.join(str(workflow.current_basedir), "config.yaml")


total_spike_fractions =  config["total_spike_fractions"]
total_depths = config["total_depths"]
reps = config["reps"]

spiked_reads = expand('{rep}_depth{depth}_spike{frac:.5f}_R{readdir}.fastq.gz',
                        rep=reps,
                        depth=total_depths,
                        frac=total_spike_fractions,
                        readdir=[1,2])
spike_stats=expand("{rep}_depth{depth}_spike{frac:.5f}.stats",
                   rep=reps,
                   depth=total_depths,
                   frac=total_spike_fractions,
                   )




localrules:
    all,
    make_input_table,

rule all:
    input:
        spiked_reads,
        spike_stats,

rule get_references:
    output:
        mockdir=directory("mock"),
        spikedir=directory("spikes"),
    shell:"""
    set -eoux pipefail
    # wget complains if this is present
    if [ -f D6331.refseq.zip ]
    then
    echo "refs present"
    else
        wget -N https://s3.amazonaws.com/zymo-files/BioPool/D6331.refseq.zip
        unzip D6331.refseq.zip
    fi
    # snakemake doesn't create outputs labeled as directories
    mkdir -p {output.mockdir} {output.spikedir} tmp_spike

    curl -o - ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/013/045/GCA_000013045.1_ASM1304v1/GCA_000013045.1_ASM1304v1_genomic.fna.gz | gunzip > tmp_spike/Salinibacter_ruber.fa
    # getting Trichoderma reesei  QM6a instead of  Trichoderma reesei ATCC 13631 .  Might be fine license-wise but not sure
    curl -o - ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/167/675/GCF_000167675.1_v2.0/GCF_000167675.1_v2.0_genomic.fna.gz | gunzip  > tmp_spike/Trichoderma_reesei.fa
    # getting CBA1121 instead of Haloarcula hispanica ATCC 33960  for the same reason.
    curl -o - ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/008/729/095/GCF_008729095.1_ASM872909v1/GCF_008729095.1_ASM872909v1_genomic.fna.gz | gunzip  > tmp_spike/Haloarcula_hispanica.fa

    for fasta in $(ls tmp_spike/*fa)
    do
      # borrowed some logic from https://www.biostars.org/p/294920/ to smoosh together sequences
      # otherwise, art with generate nreads PER Sequence, not per genome
      name=$(basename $fasta | sed "s|.fa||g")
      cat $fasta | grep -v "^>" | awk 'BEGIN {{ ORS=""; print ">${{name}}_concatenated\\n" }} {{ print }}' > {output.spikedir}/${{name}}.fasta
    done
    for fasta in D6331.refseq/genomes/*fasta
    do
      name=$(basename $fasta | sed "s|.fasta||g")
      cat $fasta | grep -v "^>" | awk 'BEGIN {{ ORS=""; print ">${{name}}_concatenated\\n" }} {{ print }}' > {output.mockdir}/${{name}}.fasta
    done
    rm -r tmp_spike

    """

rule make_input_table:
    """ this could be modified to incorporate different depth schemes per bug,
    but for a first pass we do even depths
    """
    input:
        mockdir="mock",
        spikedir="spikes",
    output:
        outtable="sim_tables/{rep}_depth{depth}_spike{frac}.tab"
    run:
        import glob
        import math
        mocks = glob.glob(input.mockdir + "/*.fasta")
        spikes= glob.glob(input.spikedir + "/*.fasta")
        depth = int(wildcards.depth)
        nmocks = len(mocks)
        nspikes = len(spikes)
        total_spike = depth * float(wildcards.frac)
        total_non_spike = depth - total_spike
        each_non_spike = math.floor(total_non_spike/nmocks)
        each_spike =  math.floor(total_spike/nspikes)
        with open(output.outtable, "w") as outf:
            for spike in spikes:
                if each_spike != 0:
                    outf.write(f"{spike}\t{each_spike}\n")
            for mock in mocks:
                if each_non_spike != 0:
                    outf.write(f"{mock}\t{each_non_spike}\n")


rule simulate:
    input:
        mockdir="mock",
        spikedir="spikes",
        intable="sim_tables/{rep}_depth{depth}_spike{frac}.tab"
    output:
        R1="{rep}_depth{depth}_spike{frac}_R1.fastq.gz",
        R2="{rep}_depth{depth}_spike{frac}_R2.fastq.gz",
    container:"docker://ghcr.io/vdblab/art:2016.06.05"
    threads: 4
    shell: """
    set -euxo pipefail

    # look a loop! could use parallel but this is a one-off for generating test data.
    tmppre="tmp_{wildcards.rep}_depth{wildcards.depth}_spike{wildcards.frac}"
    cat {input.intable} | while read ref nreads
    do
        refbase=$(basename $ref)
        art_illumina --seqSys HS25 --in $ref  --paired --len 150 --rcount $nreads --mflen 500 --sdev 10 --out ${{tmppre}}_${{refbase}}_R --rndSeed {wildcards.rep}
    done

    ls ${{tmppre}}*
    cat ${{tmppre}}*R1.fq | pigz > {output.R1}
    cat ${{tmppre}}*R2.fq | pigz > {output.R2}
    """

rule stats:
    input:
        R1="{rep}_depth{depth}_spike{frac}_R1.fastq.gz",
        R2="{rep}_depth{depth}_spike{frac}_R2.fastq.gz",
    output:
        stats="{rep}_depth{depth}_spike{frac}.stats"
    container: "docker://ghcr.io/vdblab/seqkit:2.3.1"
    threads: 8
    shell:"""
    tmppre="tmp_{wildcards.rep}_depth{wildcards.depth}_spike{wildcards.frac}"
    seqkit stats ${{tmppre}}*.fq > {output.stats}
    seqkit stats {input.R1} {input.R2} | tail -n+2  >> {output.stats}
    rm  ${{tmppre}}*
    """

# TODO: add in assembly and binning rules
